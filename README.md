# DA5401 â€“ Kaggle Data Challenge

Name: Anan madhav T V 
Roll No: MM2B013


## ğŸ“‚ Folder Structure
```
â”œâ”€â”€ final_kaggle.ipynb          # Main notebook containing the complete solution
â”œâ”€â”€ train_data.json             # Training dataset (features + scores)
â”œâ”€â”€ test_data.json              # Test dataset (features only)
â”œâ”€â”€ metric_name_embeddings.npy  # Pre-computed embeddings for metric definitions
â”œâ”€â”€ metric_names.json           # Mapping of metric names
â””â”€â”€ README.md                   # Project documentation
```

---

## âš™ï¸ How to Run

### 1ï¸âƒ£ Environment Setup
Install dependencies:
```bash
pip install sentence-transformers scikit-learn pandas numpy torch
```

### 2ï¸âƒ£ Data Placement
Ensure the following files are present:
- train_data.json
- test_data.json
- metric_name_embeddings.npy
- metric_names.json

Update `DATA_DIR` if using a custom directory.

### 3ï¸âƒ£ Execution
Run `final_kaggle.ipynb` in Jupyter/Colab/Kaggle.
The notebook:
- Preprocesses and embeds text  
- Trains via 5-Fold CV  
- Outputs `submission.csv`

---

# ğŸ“ Challenge Summary

Predicting semantic alignment between:
- A **metric definition**
- A **promptâ€“response pair**

The dataset was **heavily imbalanced**, requiring careful augmentation and modeling.

---

# ğŸš€ Solution Overview

## 1ï¸âƒ£ Data Preparation & Feature Engineering

### Text Preprocessing
Merged texts using:
```
[P] user_prompt
[R] response
[S] system_prompt
```

### Embedding Model
Used:
```
sentence-transformers/paraphrase-multilingual-mpnet-base-v2
```
â†’ 768-d embeddings each for:
- Metric definition (E_m)
- Conversation text (E_t)

### Interaction Features
To help the model compare distances:
- **L1 Distance:** |E_m - E_t|
- **Element-wise Product:** E_m âŠ™ E_t

### Final Input Vector
3072 dimensions total.

---

# 2ï¸âƒ£ Fixing Class Imbalance (Critical)

### Issue:
91% of scores were **9 or 10**, causing models to predict only high values.

### Solution: Cross-Metric Negative Sampling
- Select 50% of high-score samples (â‰¥9)
- Replace metric with a different randomly chosen metric
- Assign synthetic score = **1.0**

This forces the model to learn what *bad matches* look like.

---

# 3ï¸âƒ£ Model Architecture â€“ Two-Tower Siamese Network

### Towers
- **Tower A:** Metric embedding â†’ Dense layers
- **Tower B:** Text embedding â†’ Dense layers

### Fusion
Concatenates:
- Tower outputs
- L1 distance
- Product features

### Regression Head
BatchNorm + ReLU + Dropout â†’ Score output

---

# Training

### Optimization
- AdamW optimizer  
- Cosine Annealing LR Scheduler  
- 5-Fold Cross Validation  

---

# Results

### **Final RMSE: 2.720**

### Why It Worked
- Imbalance solved via targeted augmentation  
- Explicit similarity features improved learning  
- Siamese architecture suited dual inputs  
- 5-fold averaging stabilized predictions  

---

# Conclusion

The project shows that high performance requires:
- Proper feature engineering  
- Handling skewed labels  
- Two-tower architectures  
- Carefully designed training loops  

The combination significantly outperformed baseline models.

